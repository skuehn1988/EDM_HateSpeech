{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 3)\n",
      "(201, 3)\n",
      "      id                                            content  deleted\n",
      "313  313  Lies Dir mal das Original-Papier der Hartz Kom...    False\n",
      "138  138  ... sondern ein Nebenprodukt evolutionärer Kon...    False\n",
      "221  221                                                 ni    False\n",
      "924  924  Was willst du damit denn aussagen? Das die Neg...     True\n",
      "479  479  Ich weiß auch nicht wie sie auf 32000 kommen, ...    False\n",
      "563  563  Und was genau willst Du dann mit Keines der Ki...     True\n",
      "860  860  Böller bestellen und hoffen, dass er neutral v...     True\n",
      "814  814  Ein kluger Stratege wie Putin ist mit einem Ps...     True\n",
      "611  611                                                Blu     True\n",
      "737  737  Leider sind die Vergleiche vollkommen passend....     True\n",
      "87    87  Das Gallup-Institut meint, Sie verbreiten Fake...    False\n",
      "57    57  Warum?Die illegalen Einreisen würden drastisch...    False\n",
      "477  477  Ich habe eine VT zu dieser Situation, die zwei...    False\n",
      "551  551  Nette Satire, ersetzen Sie Russland durch USA ...     True\n",
      "895  895  Naja, sie dachten, er denkt so wie sie. Das ge...     True\n",
      "578  578               Sage mir, wer deine Freunde sind ...     True\n",
      "32    32  Ich denke du kannst verstehen, was er (Bergfür...    False\n",
      "666  666  Mir schwebt vor, daß ein Blick in alte Zeitung...     True\n",
      "944  944  Und die Justizkriminellen -Staatsanwaltschaft ...     True\n",
      "112  112  Das haben die mit Links-Grün gemeinsam.Ich sag...    False\n",
      "169  169                             DANKE - gut zu wissen.    False\n",
      "557  557  Interessant ist auch die Frage, was genau mit ...     True\n",
      "778  778  Tja, das ist schade. Ich hätte mir ja gerne ei...     True\n",
      "257  257  Bei allen wo man nicht weiß wo sie sind die So...    False\n",
      "235  235  Man kann das Fahrverbot zu Recht auf verschied...    False\n",
      "664  664  Dein gezielt-verharmlosendendes Statement zur ...     True\n",
      "307  307  Nein, denn Häuser baut nicht nur der Staat, so...    False\n",
      "339  339  Wenn schon sollten Tafel überflüssig gemacht w...    False\n",
      "893  893  ...entpuppst du dich am Ende als kleingeistige...     True\n",
      "332  332  Ob jetzt in zwanzig oder nur in fünfzehn Fälle...    False\n",
      "..   ...                                                ...      ...\n",
      "317  317  Du scheinst ein etwas merkwürdiges Verständnis...    False\n",
      "979  979  Irgendwelches die bösen Russen haben schuld-Bl...     True\n",
      "988  988                                        wirst sehen     True\n",
      "538  538  Werter Th1Meyer, sehr gerne geschehen. Ich bin...     True\n",
      "835  835  ... Rassisten, Nazis, Hetzer beschweren sich, ...     True\n",
      "71    71  in diese als die Deppen eingehen, die fest dar...    False\n",
      "252  252  so etwas kann ja nur sich ENTWICKELN, wenn an ...    False\n",
      "442  442  Zur GST gehörte auch die Deutsche Sportschütze...    False\n",
      "843  843  Ja so ein richtiger [s]Führer[s][s]Parteivorsi...     True\n",
      "516  516  Es geht mir auch nicht darum. Mir geht es eige...    False\n",
      "41    41  Im Wunderland des Sozialismus verprügeln die v...    False\n",
      "505  505  Vielleicht erleichtert ein Ziegenfell die Situ...    False\n",
      "163  163  mit Merkel und Schäuble als Gefängnisbetreiber...    False\n",
      "609  609                      alles Faschos ausser Mutti...     True\n",
      "473  473  In der Ukraine werden die Ukronazis finanziert...    False\n",
      "997  997  Habe ich hier in dem gesperrten Beitrag erklär...     True\n",
      "65    65   Dunnerschlach, da muss man erstmal drauf kommen!    False\n",
      "80    80                                                 kw    False\n",
      "323  323  Diese Quelle ist nun wirklich beachtlich: Eine...    False\n",
      "570  570  Na so richtig Freude mag da nicht aufkommen. E...     True\n",
      "152  152  Wenn vor deiner Türe also eine Menschentraube ...    False\n",
      "157  157  Du glaubst also, die frichen bleiben ruhig, wä...    False\n",
      "571  571  Aus 15 Jahren über dem Verfallsdatum kann man ...     True\n",
      "652  652  So können nur linke spinner auslegen. Also wen...     True\n",
      "606  606  Aha! Unangenehme Wahrheiten werden mit Diffami...     True\n",
      "891  891  noch jemand,  der entmenschlichung ganz okay f...     True\n",
      "619  619    Mach Deinen  Job als Subalterner Advokaten S...     True\n",
      "776  776  Wenn man Verteidigung als Aggression definiert...     True\n",
      "777  777  Is' mir schon klar. Die wollen ihre knackigen ...     True\n",
      "982  982  Haben sich diese Leibwächter tatsächlich so sc...     True\n",
      "\n",
      "[201 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = ('/Users/sebastian/Desktop/EDM Hate Speech/output_utf8_small.csv')\n",
    "data = pd.read_csv(dataset, sep=',', header=None)\n",
    "data.columns = [\"id\", \"content\", \"deleted\"]\n",
    "data.to_csv('/Users/sebastian/Desktop/EDM Hate Speech/' + \"1000.csv\", index=False)\n",
    "\n",
    "X, y = data.iloc[:,:], data.iloc[:,:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)\n",
    "\n",
    "X_train.to_csv('/Users/sebastian/Desktop/EDM Hate Speech/' + \"Train.csv\", index=False)\n",
    "X_test.to_csv('/Users/sebastian/Desktop/EDM Hate Speech/' + \"Test.csv\", index=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "801/801 [==============================] - 17s 21ms/step - loss: 0.7204 - acc: 0.4906\n",
      "Epoch 2/3\n",
      "801/801 [==============================] - 16s 20ms/step - loss: 0.6564 - acc: 0.6155\n",
      "Epoch 3/3\n",
      "801/801 [==============================] - 15s 19ms/step - loss: 0.6371 - acc: 0.6404\n",
      "201/201 [==============================] - 2s 7ms/step\n",
      "(201, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense, Input, Bidirectional, Conv1D, GRU, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "data_path = '/Users/sebastian/Desktop/EDM Hate Speech/'\n",
    "\n",
    "EMBEDDING_FILE = data_path + 'multilingual_embeddings.txt'\n",
    "\n",
    "train = pd.read_csv(data_path + 'Train.csv')\n",
    "test = pd.read_csv(data_path + 'Test.csv')\n",
    "\n",
    "x_train = train[\"content\"].fillna(\"fillna\")\n",
    "x_test = test[\"content\"].fillna(\"fillna\")\n",
    "\n",
    "x_train = x_train.str.lower()\n",
    "x_test = x_test.str.lower()\n",
    "\n",
    "y_train = train[[\"deleted\"]].values\n",
    "\n",
    "max_features = 14526\n",
    "maxlen = 150\n",
    "embed_size = 300\n",
    "\n",
    "tok = text.Tokenizer(num_words=max_features, lower=True)\n",
    "\n",
    "tok.fit_on_texts(list(x_train) + list(x_test))\n",
    "\n",
    "x_train = tok.texts_to_sequences(x_train)\n",
    "x_test = tok.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(EMBEDDING_FILE, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "word_index = tok.word_index\n",
    "\n",
    "# prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "sequence_input = Input(shape=(maxlen,))\n",
    "\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(sequence_input)\n",
    "\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))(x)\n",
    "x = Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "prediction = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(sequence_input, prediction)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "bst_model_path = '/Users/sebastian/Desktop/EDM Hate Speech/model1.h5'\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "y_pred = model.predict(x_test, verbose=1, batch_size=512)\n",
    "\n",
    "model.save_weights(bst_model_path)\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "data = pd.DataFrame(data=y_pred)\n",
    "\n",
    "data.to_csv(data_path + \"prediction.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "dataset = ('/Users/sebastian/Desktop/EDM Hate Speech/prediction.csv')\n",
    "data = pd.read_csv(dataset, header=None)\n",
    "data.columns = [\"deleted\"]\n",
    "data.drop(data.index[0], inplace=True)\n",
    "\n",
    "data.to_csv('/Users/sebastian/Desktop/EDM Hate Speech/' + \"prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1:              precision    recall  f1-score   support\n",
      "\n",
      "  not toxic       0.68      0.27      0.39       103\n",
      "      toxic       0.53      0.87      0.66        98\n",
      "\n",
      "avg / total       0.61      0.56      0.52       201\n",
      "\n",
      "Micro: 0.562189054726\n",
      "Macro: 0.523901808786\n",
      "Average: 0.52054327844\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "categories = [\"deleted\"]\n",
    "\n",
    "\n",
    "def to_binary(predictions):\n",
    "    for category in categories:\n",
    "        predictions[category] = [1 if row > 0.5 else 0 for row in predictions[category]]\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_f1_results(truth, predictions, name):\n",
    "    target_names = ['not toxic','toxic']\n",
    "    predictions = to_binary(predictions)\n",
    "\n",
    "    print(name + \": \" + str(metrics.classification_report(truth[categories], predictions[categories], target_names=target_names)))\n",
    "    print(\"Micro: \" + str(metrics.f1_score(truth[categories], predictions[categories], average='micro')))\n",
    "    print(\"Macro: \" + str(metrics.f1_score(truth[categories], predictions[categories], average='macro')))\n",
    "    print(\"Average: \" + str(metrics.f1_score(truth[categories], predictions[categories], average='weighted')))\n",
    "\n",
    "    ## print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "     ##        precision    recall  f1-score   support\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    truth = pd.read_csv(\"/Users/sebastian/Desktop/EDM Hate Speech/Test.csv\")\n",
    "\n",
    "    prediction1 = pd.read_csv(\"/Users/sebastian/Desktop/EDM Hate Speech/prediction.csv\")\n",
    "\n",
    "    get_f1_results(truth, prediction1, \"Prediction 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
